{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c9c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1e13533",
   "metadata": {},
   "source": [
    "Q1.Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90103f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1.\n",
      "Name: \"Baby Shark Dance\"[4]\n",
      "Artist: Pinkfong Baby Shark - Kids' Songs & Stories\n",
      "Upload Date: June 17, 2016\n",
      "Views: 12.85\n",
      "\n",
      "Rank: 2.\n",
      "Name: \"Despacito\"[7]\n",
      "Artist: Luis Fonsi\n",
      "Upload Date: January 12, 2017\n",
      "Views: 8.16\n",
      "\n",
      "Rank: 3.\n",
      "Name: \"Johny Johny Yes Papa\"[14]\n",
      "Artist: LooLoo Kids\n",
      "Upload Date: October 8, 2016\n",
      "Views: 6.70\n",
      "\n",
      "Rank: 4.\n",
      "Name: \"Bath Song\"[15]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: May 2, 2018\n",
      "Views: 6.20\n",
      "\n",
      "Rank: 5.\n",
      "Name: \"Shape of You\"[16]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: January 30, 2017\n",
      "Views: 6.00\n",
      "\n",
      "Rank: 6.\n",
      "Name: \"See You Again\"[19]\n",
      "Artist: Wiz Khalifa\n",
      "Upload Date: April 6, 2015\n",
      "Views: 5.89\n",
      "\n",
      "Rank: 7.\n",
      "Name: \"Phonics Song with Two Words\"[24]\n",
      "Artist: ChuChu TV\n",
      "Upload Date: March 6, 2014\n",
      "Views: 5.30\n",
      "\n",
      "Rank: 8.\n",
      "Name: \"Wheels on the Bus\"[25]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: May 24, 2018\n",
      "Views: 5.24\n",
      "\n",
      "Rank: 9.\n",
      "Name: \"Uptown Funk\"[26]\n",
      "Artist: Mark Ronson\n",
      "Upload Date: November 19, 2014\n",
      "Views: 4.92\n",
      "\n",
      "Rank: 10.\n",
      "Name: \"Learning Colors – Colorful Eggs on a Farm\"[27]\n",
      "Artist: Miroshka TV\n",
      "Upload Date: February 27, 2018\n",
      "Views: 4.89\n",
      "\n",
      "Rank: 11.\n",
      "Name: \"Gangnam Style\"[28]\n",
      "Artist: Psy\n",
      "Upload Date: July 15, 2012\n",
      "Views: 4.80\n",
      "\n",
      "Rank: 12.\n",
      "Name: \"Masha and the Bear – Recipe for Disaster\"[33]\n",
      "Artist: Get Movies\n",
      "Upload Date: January 31, 2012\n",
      "Views: 4.55\n",
      "\n",
      "Rank: 13.\n",
      "Name: \"Dame Tu Cosita\"[34]\n",
      "Artist: El Chombo\n",
      "Upload Date: April 5, 2018\n",
      "Views: 4.35\n",
      "\n",
      "Rank: 14.\n",
      "Name: \"Axel F\"[35]\n",
      "Artist: Crazy Frog\n",
      "Upload Date: June 16, 2009\n",
      "Views: 3.91\n",
      "\n",
      "Rank: 15.\n",
      "Name: \"Sugar\"[36]\n",
      "Artist: Maroon 5\n",
      "Upload Date: January 14, 2015\n",
      "Views: 3.87\n",
      "\n",
      "Rank: 16.\n",
      "Name: \"Roar\"[37]\n",
      "Artist: Katy Perry\n",
      "Upload Date: September 5, 2013\n",
      "Views: 3.80\n",
      "\n",
      "Rank: 17.\n",
      "Name: \"Counting Stars\"[38]\n",
      "Artist: OneRepublic\n",
      "Upload Date: May 31, 2013\n",
      "Views: 3.79\n",
      "\n",
      "Rank: 18.\n",
      "Name: \"Sorry\"[39]\n",
      "Artist: Justin Bieber\n",
      "Upload Date: October 22, 2015\n",
      "Views: 3.66\n",
      "\n",
      "Rank: 19.\n",
      "Name: \"Baa Baa Black Sheep\"[40]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: June 25, 2018\n",
      "Views: 3.64\n",
      "\n",
      "Rank: 20.\n",
      "Name: \"Thinking Out Loud\"[41]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: October 7, 2014\n",
      "Views: 3.60\n",
      "\n",
      "Rank: 21.\n",
      "Name: \"Waka Waka (This Time for Africa)\"[42]\n",
      "Artist: Shakira\n",
      "Upload Date: June 4, 2010\n",
      "Views: 3.59\n",
      "\n",
      "Rank: 22.\n",
      "Name: \"Dark Horse\"[43]\n",
      "Artist: Katy Perry\n",
      "Upload Date: February 20, 2014\n",
      "Views: 3.52\n",
      "\n",
      "Rank: 23.\n",
      "Name: \"Lakdi Ki Kathi\"[44]\n",
      "Artist: Jingle Toons\n",
      "Upload Date: June 14, 2018\n",
      "Views: 3.48\n",
      "\n",
      "Rank: 24.\n",
      "Name: \"Faded\"[45]\n",
      "Artist: Alan Walker\n",
      "Upload Date: December 3, 2015\n",
      "Views: 3.45\n",
      "\n",
      "Rank: 25.\n",
      "Name: \"Perfect\"[46]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: November 9, 2017\n",
      "Views: 3.45\n",
      "\n",
      "Rank: 26.\n",
      "Name: \"Let Her Go\"[47]\n",
      "Artist: Passenger\n",
      "Upload Date: July 25, 2012\n",
      "Views: 3.44\n",
      "\n",
      "Rank: 27.\n",
      "Name: \"Girls Like You\"[48]\n",
      "Artist: Maroon 5\n",
      "Upload Date: May 31, 2018\n",
      "Views: 3.42\n",
      "\n",
      "Rank: 28.\n",
      "Name: \"Humpty the train on a fruits ride\"[49]\n",
      "Artist: Kiddiestv Hindi – Nursery Rhymes & Kids Songs\n",
      "Upload Date: January 26, 2018\n",
      "Views: 3.41\n",
      "\n",
      "Rank: 29.\n",
      "Name: \"Lean On\"[50]\n",
      "Artist: Major Lazer\n",
      "Upload Date: March 22, 2015\n",
      "Views: 3.38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the most viewed videos\n",
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "\n",
    "# Find all the rows in the table except the header row\n",
    "rows = table.find_all(\"tr\")[1:30]\n",
    "\n",
    "# Scrape the details for each video\n",
    "for row in rows:\n",
    "    cells = row.find_all(\"td\")\n",
    "    \n",
    "    # Extract the desired information from the cells\n",
    "    rank = cells[0].text.strip()\n",
    "    name = cells[1].text.strip()\n",
    "    artist = cells[2].text.strip()\n",
    "    upload_date = cells[4].text.strip()\n",
    "    views = cells[3].text.strip()\n",
    "    \n",
    "    # Print the details\n",
    "    print(\"Rank:\", rank)\n",
    "    print(\"Name:\", name)\n",
    "    print(\"Artist:\", artist)\n",
    "    print(\"Upload Date:\", upload_date)\n",
    "    print(\"Views:\", views)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff4326b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ead60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91897\\AppData\\Local\\Temp\\ipykernel_17212\\3328788396.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d1eefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870ac5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                                  Bath Song   \n",
       "4    5.                               Shape of You   \n",
       "5    6.                              See You Again   \n",
       "6    7.                Phonics Song with Two Words   \n",
       "7    8.                          Wheels on the Bus   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.  Learning Colors – Colorful Eggs on a Farm   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.   Masha and the Bear – Recipe for Disaster   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                     Axel F   \n",
       "14  15.                                      Sugar   \n",
       "15  16.                                       Roar   \n",
       "16  17.                             Counting Stars   \n",
       "17  18.                                      Sorry   \n",
       "18  19.                        Baa Baa Black Sheep   \n",
       "19  20.                          Thinking Out Loud   \n",
       "20  21.           Waka Waka (This Time for Africa)   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                             Lakdi Ki Kathi   \n",
       "23  24.                                      Faded   \n",
       "24  25.                                    Perfect   \n",
       "25  26.                                 Let Her Go   \n",
       "26  27.                             Girls Like You   \n",
       "27  28.          Humpty the train on a fruits ride   \n",
       "28  29.                                    Lean On   \n",
       "29  30.                                   Bailando   \n",
       "\n",
       "                                           Artist        Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                     Crazy Frog      June 16, 2009   \n",
       "14                                       Maroon 5   January 14, 2015   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "19                                     Ed Sheeran    October 7, 2014   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                   Jingle Toons      June 14, 2018   \n",
       "23                                    Alan Walker   December 3, 2015   \n",
       "24                                     Ed Sheeran   November 9, 2017   \n",
       "25                                      Passenger      July 25, 2012   \n",
       "26                                       Maroon 5       May 31, 2018   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "28                                    Major Lazer     March 22, 2015   \n",
       "29                               Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   Views (in Billions)  \n",
       "0                12.85  \n",
       "1                 8.16  \n",
       "2                 6.70  \n",
       "3                 6.20  \n",
       "4                 6.00  \n",
       "5                 5.89  \n",
       "6                 5.30  \n",
       "7                 5.24  \n",
       "8                 4.92  \n",
       "9                 4.89  \n",
       "10                4.80  \n",
       "11                4.55  \n",
       "12                4.35  \n",
       "13                3.91  \n",
       "14                3.87  \n",
       "15                3.80  \n",
       "16                3.79  \n",
       "17                3.66  \n",
       "18                3.64  \n",
       "19                3.60  \n",
       "20                3.59  \n",
       "21                3.52  \n",
       "22                3.48  \n",
       "23                3.45  \n",
       "24                3.45  \n",
       "25                3.44  \n",
       "26                3.42  \n",
       "27                3.41  \n",
       "28                3.38  \n",
       "29                3.38  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")\n",
    "        \n",
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")\n",
    "        \n",
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")\n",
    "        \n",
    "# Scraping Upload_Date of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")\n",
    "        \n",
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")\n",
    "        \n",
    "# creating DataFrame for scraped data\n",
    "Wiki = pd.DataFrame({})\n",
    "Wiki['Rank'] = Rank\n",
    "Wiki['Name'] = Name\n",
    "Wiki['Artist'] = Artist\n",
    "Wiki['Upload Date'] = Date\n",
    "Wiki['Views (in Billions)'] = Views\n",
    "\n",
    "# removing stray numbers from Name column\n",
    "Wiki.Name = Wiki.Name.apply(lambda x:x[:-4].strip('\"'))\n",
    "Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77752012",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae9828b",
   "metadata": {},
   "source": [
    "Q2.Scrape the details teamIndia’sinternationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e45a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51112eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Hello\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9f36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \"https://www.bcci.tv/.\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c09d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening fixtures\n",
    "\n",
    "international =driver.find_element(By.XPATH,'//div[@class=\"collapse navbar-collapse\"]/ul/li[2]/a')\n",
    "try:\n",
    "    international.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(international.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f59667da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store all the scrapped result\n",
    "title = []\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "time = []\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aae6b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dominica',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Trinidad',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dominica',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Trinidad',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dominica',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Trinidad',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dominica',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Dhaka',\n",
       " 'Trinidad',\n",
       " 'Dhaka']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting title\n",
    "try:\n",
    "    title_tags=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "    for i in title_tags :\n",
    "        title.append(i.text)\n",
    "except StaleElementReferenceException:\n",
    "    title.append('--')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3f3abb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st T20I ',\n",
       " '2nd T20I ',\n",
       " '1st Test ',\n",
       " '3rd T20I ',\n",
       " '1st ODI ',\n",
       " '2nd ODI ',\n",
       " '2nd Test ',\n",
       " '3rd ODI ',\n",
       " '1st T20I ',\n",
       " '2nd T20I ',\n",
       " '1st Test ',\n",
       " '3rd T20I ',\n",
       " '1st ODI ',\n",
       " '2nd ODI ',\n",
       " '2nd Test ',\n",
       " '3rd ODI ',\n",
       " '1st T20I ',\n",
       " '2nd T20I ',\n",
       " '1st Test ',\n",
       " '3rd T20I ',\n",
       " '1st ODI ',\n",
       " '2nd ODI ',\n",
       " '2nd Test ',\n",
       " '3rd ODI ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting series\n",
    "try:\n",
    "    series_tags=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "    for i in series_tags :\n",
    "        series.append(i.text.split(\"-\")[0])\n",
    "except StaleElementReferenceException:\n",
    "    series.append('--')\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cad3e77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Windsor Park ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " \"Queen's Park Oval \",\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Windsor Park ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " \"Queen's Park Oval \",\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Windsor Park ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " 'Shere Bangla National Stadium  Mirpur ',\n",
       " \"Queen's Park Oval \",\n",
       " 'Shere Bangla National Stadium  Mirpur ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting place\n",
    "try:\n",
    "    place_tags=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "    for i in place_tags :\n",
    "        place.append(i.text.replace(',',\" \"))\n",
    "except StaleElementReferenceException:\n",
    "    place.append('--')\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3575ca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting date\n",
    "try:\n",
    "    date_tags=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "    for i in date_tags :\n",
    "        date.append(i.text)\n",
    "except StaleElementReferenceException:\n",
    "    date.append('--')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c525ffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting time\n",
    "try:\n",
    "    time_tags=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "    for i in time_tags :\n",
    "        time.append(i.text)\n",
    "except StaleElementReferenceException:\n",
    "    time.append('--')\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b2edf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting url\n",
    "url_tags=driver.find_elements(By.XPATH,'//a[@class=\"match-center-btn ng-scope\"]')\n",
    "for i in url_tags :\n",
    "    url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d83cd12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "238c89ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details team India’s international fixtures from bcci.tv.:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Series, Place, Date, Time , URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(title,series,place, date,time,url ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Title', 'Series','Place', 'Date','Time ', 'URL'])\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details team India’s international fixtures from bcci.tv.:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9329b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "636de336",
   "metadata": {},
   "source": [
    "Q3.Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98ca8e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "555e0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on ecomony tab\n",
    "\n",
    "India=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/button')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "690cdb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on India from economy tab\n",
    "state = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "driver.get(state.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77456958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian state\n",
    "\n",
    "state = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "driver.get(state.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2470d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to store all the scrapped result\n",
    "rank =[]\n",
    "state =[]\n",
    "gsdp_19_20=[]\n",
    "gsdp_18_19 =[]\n",
    "share_18_19 =[]\n",
    "GDP =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdb417c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank \n",
    "try:\n",
    "    rank_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank_tags :\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('NA')\n",
    "    \n",
    "# Extracting state name\n",
    "try:\n",
    "    state_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state_tags:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    state.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20\n",
    "try:\n",
    "    gsdp_19_20_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gsdp_19_20_tags:\n",
    "        gsdp_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19\n",
    "try:\n",
    "    gsdp_18_19_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gsdp_18_19_tags:\n",
    "        gsdp_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_18_19.append('NA')\n",
    "    \n",
    "# Extracting Share 18_19\n",
    "try:\n",
    "    share_18_19_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share_18_19_tags:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append('NA')\n",
    "    \n",
    "# Extracting GDP\n",
    "try:\n",
    "    GDP_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in GDP_tags:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8beeae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(rank))\n",
    "print(len(state))\n",
    "print(len(gsdp_19_20))\n",
    "print(len(gsdp_18_19))\n",
    "print(len(share_18_19))\n",
    "print(len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cd89fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of State-wise GDP of India from statisticstime.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank                      State GSDP_19_20 GSDP_18_19 Share_18_19  \\\n",
       "Sr. No.                                                                     \n",
       "1          1                Maharashtra          -  2,632,792      13.94%   \n",
       "2          2                 Tamil Nadu  1,845,853  1,630,208       8.63%   \n",
       "3          3              Uttar Pradesh  1,687,818  1,584,764       8.39%   \n",
       "4          4                    Gujarat          -  1,502,899       7.96%   \n",
       "5          5                  Karnataka  1,631,977  1,493,127       7.91%   \n",
       "6          6                West Bengal  1,253,832  1,089,898       5.77%   \n",
       "7          7                  Rajasthan  1,020,989    942,586       4.99%   \n",
       "8          8             Andhra Pradesh    972,782    862,957       4.57%   \n",
       "9          9                  Telangana    969,604    861,031       4.56%   \n",
       "10        10             Madhya Pradesh    906,672    809,592       4.29%   \n",
       "11        11                     Kerala          -    781,653       4.14%   \n",
       "12        12                      Delhi    856,112    774,870       4.10%   \n",
       "13        13                    Haryana    831,610    734,163       3.89%   \n",
       "14        14                      Bihar    611,804    530,363       2.81%   \n",
       "15        15                     Punjab    574,760    526,376       2.79%   \n",
       "16        16                     Odisha    521,275    487,805       2.58%   \n",
       "17        17                      Assam          -    315,881       1.67%   \n",
       "18        18               Chhattisgarh    329,180    304,063       1.61%   \n",
       "19        19                  Jharkhand    328,598    297,204       1.57%   \n",
       "20        20                Uttarakhand          -    245,895       1.30%   \n",
       "21        21            Jammu & Kashmir          -    155,956       0.83%   \n",
       "22        22           Himachal Pradesh    165,472    153,845       0.81%   \n",
       "23        23                        Goa     80,449     73,170       0.39%   \n",
       "24        24                    Tripura     55,984     49,845       0.26%   \n",
       "25        25                 Chandigarh          -     42,114       0.22%   \n",
       "26        26                 Puducherry     38,253     34,433       0.18%   \n",
       "27        27                  Meghalaya     36,572     33,481       0.18%   \n",
       "28        28                     Sikkim     32,496     28,723       0.15%   \n",
       "29        29                    Manipur     31,790     27,870       0.15%   \n",
       "30        30                   Nagaland          -     27,283       0.14%   \n",
       "31        31          Arunachal Pradesh          -     24,603       0.13%   \n",
       "32        32                    Mizoram     26,503     22,287       0.12%   \n",
       "33        33  Andaman & Nicobar Islands          -          -           -   \n",
       "\n",
       "             GDP  \n",
       "Sr. No.           \n",
       "1        399.921  \n",
       "2        247.629  \n",
       "3        240.726  \n",
       "4        228.290  \n",
       "5        226.806  \n",
       "6        165.556  \n",
       "7        143.179  \n",
       "8        131.083  \n",
       "9        130.791  \n",
       "10       122.977  \n",
       "11       118.733  \n",
       "12       117.703  \n",
       "13       111.519  \n",
       "14        80.562  \n",
       "15        79.957  \n",
       "16        74.098  \n",
       "17        47.982  \n",
       "18        46.187  \n",
       "19        45.145  \n",
       "20        37.351  \n",
       "21        23.690  \n",
       "22        23.369  \n",
       "23        11.115  \n",
       "24         7.571  \n",
       "25         6.397  \n",
       "26         5.230  \n",
       "27         5.086  \n",
       "28         4.363  \n",
       "29         4.233  \n",
       "30         4.144  \n",
       "31         3.737  \n",
       "32         3.385  \n",
       "33             -  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(rank, state,gsdp_19_20, gsdp_18_19,share_18_19 , GDP))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Rank', 'State', 'GSDP_19_20','GSDP_18_19','Share_18_19' , 'GDP'],\n",
    "                index=pd.RangeIndex(start=1, stop=34, name='Sr. No.'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of State-wise GDP of India from statisticstime.com:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea2d8e",
   "metadata": {},
   "source": [
    "Q4.Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c190f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e0e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91897\\AppData\\Local\\Temp\\ipykernel_30452\\1690777593.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://github.com/You\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9bf00b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: 'url' must be a string\n  (Session info: chrome=114.0.5735.199)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00C9A813+48355]\n\t(No symbol) [0x00C2C4B1]\n\t(No symbol) [0x00B35358]\n\t(No symbol) [0x00B8CF98]\n\t(No symbol) [0x00B7A73C]\n\t(No symbol) [0x00B8C922]\n\t(No symbol) [0x00B7A536]\n\t(No symbol) [0x00B582DC]\n\t(No symbol) [0x00B593DD]\n\tGetHandleVerifier [0x00EFAABD+2539405]\n\tGetHandleVerifier [0x00F3A78F+2800735]\n\tGetHandleVerifier [0x00F3456C+2775612]\n\tGetHandleVerifier [0x00D251E0+616112]\n\t(No symbol) [0x00C35F8C]\n\t(No symbol) [0x00C32328]\n\t(No symbol) [0x00C3240B]\n\t(No symbol) [0x00C24FF7]\n\tBaseThreadInitThunk [0x770A7D59+25]\n\tRtlInitializeExceptionChain [0x77E0B74B+107]\n\tRtlClearBits [0x77E0B6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Clicking on button tab\u001b[39;00m\n\u001b[0;32m      3\u001b[0m button \u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbutton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhref\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:449\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: 'url' must be a string\n  (Session info: chrome=114.0.5735.199)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00C9A813+48355]\n\t(No symbol) [0x00C2C4B1]\n\t(No symbol) [0x00B35358]\n\t(No symbol) [0x00B8CF98]\n\t(No symbol) [0x00B7A73C]\n\t(No symbol) [0x00B8C922]\n\t(No symbol) [0x00B7A536]\n\t(No symbol) [0x00B582DC]\n\t(No symbol) [0x00B593DD]\n\tGetHandleVerifier [0x00EFAABD+2539405]\n\tGetHandleVerifier [0x00F3A78F+2800735]\n\tGetHandleVerifier [0x00F3456C+2775612]\n\tGetHandleVerifier [0x00D251E0+616112]\n\t(No symbol) [0x00C35F8C]\n\t(No symbol) [0x00C32328]\n\t(No symbol) [0x00C3240B]\n\t(No symbol) [0x00C24FF7]\n\tBaseThreadInitThunk [0x770A7D59+25]\n\tRtlInitializeExceptionChain [0x77E0B74B+107]\n\tRtlClearBits [0x77E0B6CF+191]\n"
     ]
    }
   ],
   "source": [
    "# Clicking on button tab\n",
    "\n",
    "button =driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button')\n",
    "driver.get(button.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "772558c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "title=[]\n",
    "description=[]\n",
    "count =[]\n",
    "language =[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "553ca6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Share 18_19\n",
    "try:\n",
    "    title_tags =driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title_tags:\n",
    "        title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    title.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9654a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eab89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting URL\n",
    "\n",
    "try:\n",
    "    url_tags =driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "    for i in url_tags:\n",
    "        url.append(i.get_attribute(\"href\"))\n",
    "except NoSuchElementException:\n",
    "    url.append('NA')\n",
    "len(url)\n",
    "\n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        count_tags=driver.find_element(By.XPATH, \"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        count.append(count_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        count.append('NA')\n",
    "        \n",
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scraping Language\n",
    "    L =[]\n",
    "    try:\n",
    "        language_tag =driver.find_elements(By.XPATH,\"//li[@class='d-inline']//a//span[1]\")\n",
    "        if language_tag:\n",
    "            for j in language_tag:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        language.append('NA')\n",
    "        time.sleep(10)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc6a9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detail of trending Repository on Github.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Count</th>\n",
       "      <th>Language</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr. No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Title Description Count Language  URL\n",
       "Sr. No.                                      \n",
       "1         NaN         NaN   NaN      NaN  NaN\n",
       "2         NaN         NaN   NaN      NaN  NaN\n",
       "3         NaN         NaN   NaN      NaN  NaN\n",
       "4         NaN         NaN   NaN      NaN  NaN\n",
       "5         NaN         NaN   NaN      NaN  NaN\n",
       "6         NaN         NaN   NaN      NaN  NaN\n",
       "7         NaN         NaN   NaN      NaN  NaN\n",
       "8         NaN         NaN   NaN      NaN  NaN\n",
       "9         NaN         NaN   NaN      NaN  NaN\n",
       "10        NaN         NaN   NaN      NaN  NaN\n",
       "11        NaN         NaN   NaN      NaN  NaN\n",
       "12        NaN         NaN   NaN      NaN  NaN\n",
       "13        NaN         NaN   NaN      NaN  NaN\n",
       "14        NaN         NaN   NaN      NaN  NaN\n",
       "15        NaN         NaN   NaN      NaN  NaN\n",
       "16        NaN         NaN   NaN      NaN  NaN\n",
       "17        NaN         NaN   NaN      NaN  NaN\n",
       "18        NaN         NaN   NaN      NaN  NaN\n",
       "19        NaN         NaN   NaN      NaN  NaN\n",
       "20        NaN         NaN   NaN      NaN  NaN\n",
       "21        NaN         NaN   NaN      NaN  NaN\n",
       "22        NaN         NaN   NaN      NaN  NaN\n",
       "23        NaN         NaN   NaN      NaN  NaN\n",
       "24        NaN         NaN   NaN      NaN  NaN\n",
       "25        NaN         NaN   NaN      NaN  NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list= list(zip(title,description,count,language,url ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Title', 'Description', 'Count','Language','URL'],\n",
    "                  index=pd.RangeIndex(start=1, stop=26, name='Sr. No.'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Detail of trending Repository on Github.com:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cd05e",
   "metadata": {},
   "source": [
    "Q5.Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "989d2972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "408aaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\" https:/www.billboard.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2769fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on button tab\n",
    "\n",
    "button =driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "driver.get(button.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b740e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on hot100 tab\n",
    "\n",
    "hot100 =driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a')\n",
    "driver.get(hot100.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97ec6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List for scrapped datas\n",
    "\n",
    "name =[]\n",
    "artist =[]\n",
    "rank=[]\n",
    "peak_rank =[]\n",
    "weeks =[]\n",
    "all_info=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4100bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Song Name\n",
    "try:\n",
    "    song_tags =driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li/h3')\n",
    "    for i in song_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')\n",
    "    \n",
    "all_info=[]\n",
    "try:\n",
    "    all_tags =driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li/span')\n",
    "    for i in all_tags:\n",
    "        all_info.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    all_info.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a874699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping artist\n",
    "artist= all_info[0:401]\n",
    "\n",
    "# Scraping rank\n",
    "rank= all_info[1:401]\n",
    "\n",
    "# Scraping rank\n",
    "peak_rank= all_info[2:401]\n",
    "\n",
    "# Scraping weeks\n",
    "weeks= all_info[3:401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "471a955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "efc38746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of the top 100 songs on Billiboard.com.:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This_week_rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Song_name Artist_name Last_week_rank Peak_rank Weeks on board\n",
       "This_week_rank                                                              \n",
       "1                    NaN         NaN            NaN       NaN            NaN\n",
       "2                    NaN         NaN            NaN       NaN            NaN\n",
       "3                    NaN         NaN            NaN       NaN            NaN\n",
       "4                    NaN         NaN            NaN       NaN            NaN\n",
       "5                    NaN         NaN            NaN       NaN            NaN\n",
       "...                  ...         ...            ...       ...            ...\n",
       "96                   NaN         NaN            NaN       NaN            NaN\n",
       "97                   NaN         NaN            NaN       NaN            NaN\n",
       "98                   NaN         NaN            NaN       NaN            NaN\n",
       "99                   NaN         NaN            NaN       NaN            NaN\n",
       "100                  NaN         NaN            NaN       NaN            NaN\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,artist,rank,peak_rank,weeks ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Song_name', 'Artist_name', 'Last_week_rank','Peak_rank','Weeks on board'],\n",
    "                  index=pd.RangeIndex(start=1, stop=101, name='This_week_rank'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of the top 100 songs on Billiboard.com.:\\n\")\n",
    "data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d4f8c",
   "metadata": {},
   "source": [
    "Q6.. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "448b26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"  https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e54fc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists for scrapped data\n",
    "\n",
    "book =[]\n",
    "author =[]\n",
    "volumes_sold =[]\n",
    "publisher =[]\n",
    "genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e063918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "try:\n",
    "    book_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book_tags:\n",
    "        book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    book.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f5dc922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "516c82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book author's\n",
    "try:\n",
    "    author_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    author.append('NA')\n",
    "    \n",
    "\n",
    "# Scraping Volumes sold\n",
    "try:\n",
    "    volumes_sold_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in volumes_sold_tags :\n",
    "        volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    volumes_sold.append('NA')\n",
    "    \n",
    "    \n",
    "# Scraping publisher\n",
    "try:\n",
    "    publisher_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher_tags :\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    publisher.append('NA')\n",
    "    \n",
    "    \n",
    "# Scraping genre\n",
    "try:\n",
    "    genre_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre_tags :\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82151b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of the Highest Selling Novels.:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Book_ Author</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Book      Book_ Author  \\\n",
       "Rank                                                                        \n",
       "1                                     Da Vinci Code,The        Brown, Dan   \n",
       "2                  Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3              Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4             Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5                                  Fifty Shades of Grey      James, E. L.   \n",
       "...                                                 ...               ...   \n",
       "96                                            Ghost,The    Harris, Robert   \n",
       "97                       Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98                Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99    Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100   Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "     Volumes_Sold        Publisher                        Genre  \n",
       "Rank                                                             \n",
       "1       5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "2       4,475,152       Bloomsbury           Children's Fiction  \n",
       "3       4,200,654       Bloomsbury           Children's Fiction  \n",
       "4       4,179,479       Bloomsbury           Children's Fiction  \n",
       "5       3,758,936     Random House              Romance & Sagas  \n",
       "...           ...              ...                          ...  \n",
       "96        807,311     Random House   General & Literary Fiction  \n",
       "97        794,201          Penguin        Food & Drink: General  \n",
       "98        792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99        791,507            Orion           Biography: General  \n",
       "100       791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(book,author,volumes_sold,publisher,genre ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Book', 'Book_ Author', 'Volumes_Sold','Publisher','Genre'],\n",
    "                  index=pd.RangeIndex(start=1, stop=101, name='Rank'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of the Highest Selling Novels.:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745d2b2",
   "metadata": {},
   "source": [
    "Q7.Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75cf26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\" https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4db701a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List for scrapped data\n",
    "\n",
    "name =[]\n",
    "year=[]\n",
    "genre =[]\n",
    "run_time =[]\n",
    "ratings =[]\n",
    "votes =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c4ad357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name \n",
    "try:\n",
    "    name_tags =driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in name_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')\n",
    "    \n",
    "# Scraping Year span\n",
    "try:\n",
    "    year_tags =driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in year_tags :\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre_tags =driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in genre_tags :\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('NA')\n",
    "    \n",
    "# Scraping Run Time \n",
    "try:\n",
    "    run_time_tags =driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in run_time_tags :\n",
    "        run_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    run_time.append('NA')\n",
    "    \n",
    "# Scraping Ratings\n",
    "try:\n",
    "    ratings_tags =driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in ratings_tags :\n",
    "        ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    ratings.append('NA')\n",
    "\n",
    "# Scraping Votes\n",
    "try:\n",
    "    votes_tags =driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "    for i in votes_tags :\n",
    "        votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5fc87ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(name))\n",
    "print(len(genre))\n",
    "print(len(year))\n",
    "print(len(run_time))\n",
    "print(len(ratings))\n",
    "print(len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ded3fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of most watched tv series of all time from imdb.com. :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,176,675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,253,928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,033,736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303,917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>263,089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>52,024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>208,784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>260,785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name    Year span                     Genre  \\\n",
       "Rank                                                                          \n",
       "1                    Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "2                    Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "3                   The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "4                     13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "5                            The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "...                              ...          ...                       ...   \n",
       "96                             Reign  (2013–2017)                     Drama   \n",
       "97    A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "98                    Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "99             Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "100       The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "     Run_Time Ratings      Votes  \n",
       "Rank                              \n",
       "1      57 min     9.2  2,176,675  \n",
       "2      51 min     8.7  1,253,928  \n",
       "3      44 min     8.1  1,033,736  \n",
       "4      60 min     7.5    303,917  \n",
       "5      43 min     7.6    263,089  \n",
       "...       ...     ...        ...  \n",
       "96     42 min     7.4     52,024  \n",
       "97     50 min     7.8     64,047  \n",
       "98     42 min     8.1    208,784  \n",
       "99     45 min       7     43,431  \n",
       "100   572 min     8.6    260,785  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,year,genre,run_time,ratings,votes ))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Name','Year span','Genre', 'Run_Time','Ratings','Votes'],\n",
    "                  index=pd.RangeIndex(start=1, stop=101, name='Rank'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of most watched tv series of all time from imdb.com. :\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29bfb75",
   "metadata": {},
   "source": [
    "Q8.Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67e053f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\" https://archive.ics.uci.edu/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea5c38a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (99575584.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [90]\u001b[1;36m\u001b[0m\n\u001b[1;33m    dataset=driver.find_element(By.XPATH,\"//a[@href=\"/datasets\"]\")\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Clicking on all datasets links\n",
    "dataset=driver.find_element(By.XPATH,\"//a[@href=\"/datasets\"]\")\n",
    "dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f158fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scrapped data\n",
    "\n",
    "name =[]\n",
    "dtype =[]\n",
    "task =[]\n",
    "attribute_type =[]\n",
    "no_of_instances =[]\n",
    "no_of_Attri=[]\n",
    "year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a3dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping DataSet Name\n",
    "\n",
    "try:\n",
    "    name_tags =driver.find_elements(By.XPATH,\"//p[@class='normal']/b/a\")\n",
    "    for i in name_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')\n",
    "    \n",
    "# Scraping Data Type\n",
    "try:\n",
    "    dtype_tags=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "    for i in dtype_tags[1:]:\n",
    "        dtype.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    dtype.append('NA')\n",
    "    \n",
    "# Scraping Task\n",
    "try:\n",
    "    task_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in task_tags [1:]:\n",
    "        task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    task.append('NA')\n",
    "    \n",
    "# Scraping Attribute_Type\n",
    "try:\n",
    "    attribute_type_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "    for i in attribute_type_tags[1:]:\n",
    "        attribute_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    attribute_type.append('NA')\n",
    "    \n",
    "# Scraping No_of_Instances\n",
    "try:\n",
    "    no_of_instances_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "    for i in no_of_instances_tags [1:]:\n",
    "        no_of_instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_instances.append('NA')\n",
    "\n",
    "# Scraping No_of_Attribute\n",
    "try:\n",
    "    no_of_Attri_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "    for i in no_of_Attri_tags [1:]:\n",
    "        no_of_Attri.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_Attri.append('NA')\n",
    "    \n",
    "# Scraping Year\n",
    "try:\n",
    "    year_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "    for i in year_tags[1:]:\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year.append('NA')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "26fcfd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of the Datasets from UCI machine learning repositories :\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Data Type Task Attribute_Type No_of_Instances No_of_Attribute Year\n",
       "Sr No                                                                        \n",
       "1      NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "2      NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "3      NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "4      NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "5      NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "...    ...       ...  ...            ...             ...             ...  ...\n",
       "618    NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "619    NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "620    NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "621    NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "622    NaN       NaN  NaN            NaN             NaN             NaN  NaN\n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,dtype,task,attribute_type,no_of_instances,no_of_Attri,year))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Name','Data Type','Task', 'Attribute_Type','No_of_Instances','No_of_Attribute','Year'],\n",
    "                  index=pd.RangeIndex(start=1, stop=623, name='Sr No'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of the Datasets from UCI machine learning repositories :\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04502416",
   "metadata": {},
   "source": [
    "Q9.Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "22688b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "447ae60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\91741\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/data-science-recruiters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8941d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List for scrapped datas\n",
    "name=[] \n",
    "designation=[] \n",
    "company=[] \n",
    "skills=[]\n",
    "url=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b4b1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping name\n",
    "try:\n",
    "    name_tags =driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "    for i in name_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')\n",
    "    \n",
    "# Scraping designation\n",
    "try:\n",
    "    des_tags =driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "    for i in des_tags:\n",
    "        designation.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    designation.append('NA')\n",
    "\n",
    "\n",
    "# Scraping company\n",
    "comp=[]\n",
    "try:\n",
    "    com_tags =driver.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]')\n",
    "    for i in com_tags:\n",
    "        comp.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    comp.append('NA')\n",
    "    \n",
    "for i in range(0, len(comp)):\n",
    "    if i %2==1:\n",
    "        company.append(comp[i])\n",
    "        \n",
    "        \n",
    "# Scraping skills\n",
    "try:\n",
    "    skills_tags =driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "    for i in skills_tags:\n",
    "        skills.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    skills.append('NA')\n",
    "    \n",
    "    \n",
    "# Scraping url\n",
    "try:\n",
    "    url_tags =driver.find_elements(By.XPATH,'//div[@class=\"recImg mid_pImg_Silht\"]/a')\n",
    "    for i in url_tags:\n",
    "        url.append(i.get_attribute(\"href\"))\n",
    "except NoSuchElementException:\n",
    "    url.append('NA')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c788adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of Data science recruiters from naukri.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Designation Company Skills  URL\n",
       "Sr No                                     \n",
       "1      NaN         NaN     NaN    NaN  NaN\n",
       "2      NaN         NaN     NaN    NaN  NaN\n",
       "3      NaN         NaN     NaN    NaN  NaN\n",
       "4      NaN         NaN     NaN    NaN  NaN\n",
       "5      NaN         NaN     NaN    NaN  NaN\n",
       "6      NaN         NaN     NaN    NaN  NaN\n",
       "7      NaN         NaN     NaN    NaN  NaN\n",
       "8      NaN         NaN     NaN    NaN  NaN\n",
       "9      NaN         NaN     NaN    NaN  NaN\n",
       "10     NaN         NaN     NaN    NaN  NaN\n",
       "11     NaN         NaN     NaN    NaN  NaN\n",
       "12     NaN         NaN     NaN    NaN  NaN\n",
       "13     NaN         NaN     NaN    NaN  NaN\n",
       "14     NaN         NaN     NaN    NaN  NaN\n",
       "15     NaN         NaN     NaN    NaN  NaN\n",
       "16     NaN         NaN     NaN    NaN  NaN\n",
       "17     NaN         NaN     NaN    NaN  NaN\n",
       "18     NaN         NaN     NaN    NaN  NaN\n",
       "19     NaN         NaN     NaN    NaN  NaN\n",
       "20     NaN         NaN     NaN    NaN  NaN\n",
       "21     NaN         NaN     NaN    NaN  NaN\n",
       "22     NaN         NaN     NaN    NaN  NaN\n",
       "23     NaN         NaN     NaN    NaN  NaN\n",
       "24     NaN         NaN     NaN    NaN  NaN\n",
       "25     NaN         NaN     NaN    NaN  NaN\n",
       "26     NaN         NaN     NaN    NaN  NaN\n",
       "27     NaN         NaN     NaN    NaN  NaN\n",
       "28     NaN         NaN     NaN    NaN  NaN\n",
       "29     NaN         NaN     NaN    NaN  NaN\n",
       "30     NaN         NaN     NaN    NaN  NaN\n",
       "31     NaN         NaN     NaN    NaN  NaN\n",
       "32     NaN         NaN     NaN    NaN  NaN\n",
       "33     NaN         NaN     NaN    NaN  NaN\n",
       "34     NaN         NaN     NaN    NaN  NaN\n",
       "35     NaN         NaN     NaN    NaN  NaN\n",
       "36     NaN         NaN     NaN    NaN  NaN\n",
       "37     NaN         NaN     NaN    NaN  NaN\n",
       "38     NaN         NaN     NaN    NaN  NaN\n",
       "39     NaN         NaN     NaN    NaN  NaN\n",
       "40     NaN         NaN     NaN    NaN  NaN\n",
       "41     NaN         NaN     NaN    NaN  NaN\n",
       "42     NaN         NaN     NaN    NaN  NaN\n",
       "43     NaN         NaN     NaN    NaN  NaN\n",
       "44     NaN         NaN     NaN    NaN  NaN\n",
       "45     NaN         NaN     NaN    NaN  NaN\n",
       "46     NaN         NaN     NaN    NaN  NaN\n",
       "47     NaN         NaN     NaN    NaN  NaN\n",
       "48     NaN         NaN     NaN    NaN  NaN\n",
       "49     NaN         NaN     NaN    NaN  NaN\n",
       "50     NaN         NaN     NaN    NaN  NaN"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame for scrapped data\n",
    "\n",
    "data_list= list(zip(name,designation,company,skills,url))\n",
    "\n",
    "data= pd.DataFrame(data_list, \n",
    "    columns =['Name', 'Designation', 'Company','Skills','URL'],\n",
    "                  index=pd.RangeIndex(start=1, stop=51, name='Sr No'))\n",
    "\n",
    "#Print the required data\n",
    "\n",
    "print (\"Details of Data science recruiters from naukri.com:\\n\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2d0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
